# Red Neuronal XOR con M√©todos de Integraci√≥n Num√©rica

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyQt6](https://img.shields.io/badge/PyQt6-6.x+-green.svg)](https://pypi.org/project/PyQt6/)
[![NumPy](https://img.shields.io/badge/NumPy-1.21+-orange.svg)](https://numpy.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.5+-red.svg)](https://matplotlib.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## üìã Descripci√≥n

Este proyecto implementa una **red neuronal feedforward** para resolver el problema XOR utilizando diferentes **m√©todos de integraci√≥n num√©rica** aplicados a la optimizaci√≥n de pesos. El proyecto combina conceptos de **ecuaciones diferenciales ordinarias (EDO)** con **aprendizaje autom√°tico**, ofreciendo una perspectiva √∫nica sobre c√≥mo los m√©todos num√©ricos influyen en la convergencia y estabilidad del entrenamiento.

### üéØ Objetivo Acad√©mico

Demostrar y comparar c√≥mo diferentes m√©todos de integraci√≥n num√©rica afectan el proceso de optimizaci√≥n en redes neuronales, tratando el entrenamiento como la soluci√≥n de un sistema de EDO:

```
dW/dt = -Œ∑ * ‚àáL(W)
```

Donde:
- `W`: Pesos de la red neuronal
- `Œ∑`: Tasa de aprendizaje (paso de integraci√≥n)
- `‚àáL`: Gradiente de la funci√≥n de p√©rdida

## üî¨ M√©todos de Integraci√≥n Implementados

| M√©todo | Orden | Evaluaciones/Paso | Precisi√≥n | Descripci√≥n |
|--------|-------|-------------------|-----------|-------------|
| **Euler Expl√≠cito** | O(h) | 1 | B√°sica | M√©todo m√°s simple, r√°pido pero menos preciso |
| **Runge-Kutta 4 (RK4)** | O(h‚Å¥) | 4 | Alta | M√©todo cl√°sico de alta precisi√≥n |
| **Runge-Kutta 4 (RK4)** | O(h‚Å¥) | 4 | Alta | M√©todo cl√°sico de alta precisi√≥n |

### üìä F√≥rmulas Matem√°ticas

#### Euler Expl√≠cito
```
W(t+h) = W(t) + h * f(t, W(t))
```



#### Runge-Kutta 4
```
k‚ÇÅ = h * f(t, W)
k‚ÇÇ = h * f(t + h/2, W + k‚ÇÅ/2)
k‚ÇÉ = h * f(t + h/2, W + k‚ÇÇ/2)
k‚ÇÑ = h * f(t + h, W + k‚ÇÉ)
W(t+h) = W(t) + (k‚ÇÅ + 2k‚ÇÇ + 2k‚ÇÉ + k‚ÇÑ)/6
```

## üèóÔ∏è Arquitectura de la Red Neuronal

```
Entrada (2) ‚Üí Capa Oculta (3) ‚Üí Salida (1)
```

- **Entrada**: 2 neuronas (bits para XOR)
- **Capa Oculta**: 3 neuronas con activaci√≥n sigmoide
- **Salida**: 1 neurona con activaci√≥n sigmoide
- **Funci√≥n de P√©rdida**: Error Cuadr√°tico Medio (MSE)

### üìà Problema XOR

| Entrada A | Entrada B | Salida Esperada |
|-----------|-----------|-----------------|
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 0 |

## üöÄ Caracter√≠sticas


### ‚ú® Funcionalidades Principales

- **Modos de Entrenamiento**: Manual (Euler/RK4), Keras (TensorFlow), SciPy ODE
- **Selecci√≥n de M√©todo Manual**: ComboBox para elegir Euler o RK4
- **Entrenamiento Completo**: Optimizaci√≥n autom√°tica con el modo y m√©todo seleccionados
- **Modo Paso a Paso (Manual)**: Permite ejecutar un paso de integraci√≥n y visualizar gradientes y pesos
- **Visualizaci√≥n Din√°mica**: Curva de p√©rdida y visualizaci√≥n gr√°fica de la red y sus pesos en tiempo real (solo modo Manual)
- **Interfaz Gr√°fica Intuitiva (Principal)**: GUI desarrollada en PyQt6 con panel de control, √°rea de resultados y visualizaci√≥n. La aplicaci√≥n de escritorio PyQt6 es la interfaz recomendada para exploraci√≥n interactiva y visualizaciones en tiempo real.

### üé® Interfaz Gr√°fica

- **Panel de Control**: Configuraci√≥n de hiperpar√°metros
- **Selector de M√©todo**: ComboBox para m√©todos de integraci√≥n
- **√Årea de Resultados**: Informaci√≥n detallada del entrenamiento
- **Visualizaci√≥n**: Gr√°ficos de convergencia con matplotlib
- **Controles**: Botones para entrenar, paso a paso, y reset

## üì¶ Instalaci√≥n

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Dependencias (recomendado)

Instale las dependencias principales para la versi√≥n PyQt6:

```powershell
pip install numpy matplotlib PyQt6
```

Si prefiere usar un archivo de requerimientos, puede crear o usar `requirements-pyqt.txt` y ejecutar:

```powershell
pip install -r requirements-pyqt.txt
```

### Instalaci√≥n Manual (r√°pida)

```powershell
# Clonar el repositorio
git clone https://github.com/NicoAV2311/final_ecuaciones_diferenciales.git

# Navegar al directorio
cd final_ecuaciones_diferenciales

# Instalar dependencias (PyQt6)
pip install -r requirements-pyqt.txt  # o pip install numpy matplotlib PyQt6

# Ejecutar la aplicaci√≥n PyQt6 (ventana de escritorio)
python "app_pyqt6.py"
```

## üéÆ Uso

### Ejecuci√≥n B√°sica (PyQt6)

Ejecute la interfaz de escritorio PyQt6:

```powershell
python "app_pyqt6.py"
```

La ventana mostrar√° controles para la tasa de aprendizaje, n√∫mero de √©pocas y m√©todo (Euler o RK4). La pesta√±a "Red y pesos" permite inspeccionar los pesos y su evoluci√≥n durante el entrenamiento.


### Interfaz de Usuario (PyQt6)

1. **Configurar Par√°metros**:
   - Tasa de aprendizaje (Œ∑): por ejemplo 0.01 - 0.3
   - √âpocas: 200 - 10000
   - M√©todo de integraci√≥n (Manual): Euler o RK4
   - Frecuencia de actualizaci√≥n gr√°fica: controla cada cu√°ntas √©pocas se refresca la vista (p. ej. 10‚Äì200)

2. **Entrenar la red**:
   - Pulsa "Entrenar red" para iniciar el entrenamiento en un hilo de fondo.
   - Observa la curva de p√©rdida y la pesta√±a "Red y pesos" para ver c√≥mo cambian los pesos en tiempo real.

3. **Detener / Resetear**:
   - "Detener" interrumpe el entrenamiento en curso.
   - "Resetear" limpia la interfaz y el estado interno.

### Ejemplo de Uso Program√°tico

```python
from app_pyqt6 import SimpleNN

# Crear red con m√©todo RK4 (Manual)
nn = SimpleNN(eta=0.1, epochs=2000, method="RK4")
predictions = nn.train()
print(f"P√©rdida final: {nn.loss_history[-1]:.6f}")
print(f"Predicciones: {predictions}")
```

## üìä Resultados Esperados


### Convergencia T√≠pica

- **Euler**: Convergencia lenta, posible inestabilidad con Œ∑ alto
- **RK4**: Convergencia r√°pida y estable, mayor costo computacional

### M√©tricas de Rendimiento

```
M√©todo | Precisi√≥n Final | √âpocas para 99% | Estabilidad
-------|----------------|-----------------|------------
Euler  | 95-98%         | 3000-5000       | Media
RK4    | 99-100%        | 1000-2000       | Muy Alta
```

## üß™ Ejemplos de Experimentos


### Comparaci√≥n de M√©todos

```python
# Configuraci√≥n experimental
methods = ["Euler", "RK4"]
learning_rates = [0.05, 0.1, 0.2]
epochs = 2000

for method in methods:
   for lr in learning_rates:
      nn = SimpleNN(eta=lr, epochs=epochs, method=method)
      predictions = nn.train()
      # Analizar convergencia...
```

## üìÅ Estructura del Proyecto (resumen)

```
final_ecuaciones_diferenciales/
‚îÇ
‚îú‚îÄ‚îÄ app_pyqt6.py                     # Interfaz de escritorio PyQt6 (recomendada)
‚îú‚îÄ‚îÄ Tentativo final ecuaciones.py    # Versi√≥n original / archivo legacy
‚îú‚îÄ‚îÄ README.md                        # Este archivo
‚îú‚îÄ‚îÄ requirements-pyqt.txt            # Dependencias para la versi√≥n PyQt6
‚îú‚îÄ‚îÄ LICENSE                          # Licencia del proyecto
‚îÇ
‚îî‚îÄ‚îÄ docs/                            # Documentaci√≥n adicional
   ‚îú‚îÄ‚îÄ mathematical_background.md   # Fundamentos matem√°ticos
   ‚îî‚îÄ‚îÄ user_guide.md               # Gu√≠a detallada de usuario
```

## üîß Configuraci√≥n Avanzada

### Par√°metros de Red

```python
# Arquitectura personalizable
self.W1 = np.random.randn(2, 3)  # Pesos entrada-oculta
self.b1 = np.zeros((1, 3))       # Sesgos capa oculta
self.W2 = np.random.randn(3, 1)  # Pesos oculta-salida
self.b2 = np.zeros((1, 1))       # Sesgos salida
```

### Hiperpar√°metros Recomendados

| M√©todo | Œ∑ (Tasa de Aprendizaje) | √âpocas | Observaciones |
|--------|-------------------------|--------|---------------|
| Euler  | 0.05 - 0.1             | 3000+ | Reducir Œ∑ si hay inestabilidad |
| RK4    | 0.1 - 0.3              | 1500+ | Permite Œ∑ m√°s altos |
| RK4    | 0.1 - 0.3              | 1500+ | Permite Œ∑ m√°s altos |

## üìñ Fundamentos Te√≥ricos

### Ecuaciones Diferenciales en ML

El entrenamiento de redes neuronales puede modelarse como:

```
dW/dt = -‚àáL(W)
```

Este enfoque permite aplicar m√©todos de integraci√≥n num√©rica desarrollados para EDO al contexto de optimizaci√≥n en aprendizaje autom√°tico.

### Ventajas del Enfoque EDO

1. **Perspectiva Continua**: Visualizar el entrenamiento como flujo continuo
2. **An√°lisis de Estabilidad**: Aplicar teor√≠a de EDO para estudiar convergencia
3. **M√©todos Adaptativos**: Potencial para control autom√°tico del paso
4. **Interpretabilidad**: Conexi√≥n clara entre matem√°ticas y ML

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear un Pull Request


### √Åreas de Mejora

- [ ] Implementar m√©todos adaptativos (RK45, Dormand-Prince)
- [ ] A√±adir soporte para problemas multi-clase
- [ ] Integrar m√©tricas avanzadas de an√°lisis num√©rico
- [ ] Desarrollar interfaz web con visualizaciones interactivas
- [ ] Implementar comparaci√≥n autom√°tica de m√©todos

### Recursos Adicionales

- [Documentaci√≥n NumPy](https://numpy.org/doc/)
- [PyQt6 / Qt for Python Documentation](https://doc.qt.io/qtforpython/)
- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/)

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.

## üë®‚Äçüíª Autor

**Nicols Arango Vergara**
- GitHub: [@NicoAV2311](https://github.com/NicoAV2311)
- Universidad: Universidad Catolica Luis Amigo
- Materia: Ecuaciones Diferenciales

## üìû Contacto

Si tienes preguntas, sugerencias o encuentras alg√∫n problema:

- üêõ **Issues**: [GitHub Issues](https://github.com/NicoAV2311/final_ecuaciones_diferenciales/issues)
- üí¨ **Discusiones**: [GitHub Discussions](https://github.com/NicoAV2311/final_ecuaciones_diferenciales/discussions)

---

<div align="center">

**‚≠ê Si este proyecto te fue √∫til, por favor dale una estrella en GitHub ‚≠ê**

*Proyecto desarrollado como trabajo final para la materia de Ecuaciones Diferenciales*

</div>